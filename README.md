<div align="center">

# üéØ Arbeit - Intelligent Job Monitoring Platform

**Set your preferences once, never miss a relevant job opportunity again.**

[![Python](https://img.shields.io/badge/Python-3.11+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104-009688?style=for-the-badge&logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15-336791?style=for-the-badge&logo=postgresql&logoColor=white)](https://www.postgresql.org/)
[![Redis](https://img.shields.io/badge/Redis-7-DC382D?style=for-the-badge&logo=redis&logoColor=white)](https://redis.io/)
[![Docker](https://img.shields.io/badge/Docker-Compose-2496ED?style=for-the-badge&logo=docker&logoColor=white)](https://www.docker.com/)
[![Celery](https://img.shields.io/badge/Celery-5.3-37814A?style=for-the-badge&logo=celery&logoColor=white)](https://docs.celeryq.dev/)

[![Tests](https://img.shields.io/badge/Tests-50%20Passed-success?style=for-the-badge&logo=pytest)]()
[![Coverage](https://img.shields.io/badge/Coverage-90%25-brightgreen?style=for-the-badge&logo=codecov)]()
[![Code Style](https://img.shields.io/badge/Code%20Style-Black-000000?style=for-the-badge&logo=python)](https://github.com/psf/black)
[![License](https://img.shields.io/badge/License-MIT-yellow?style=for-the-badge)]()

[Features](#Key-Features) ‚Ä¢ [Quick Start](#Quick-Start) ‚Ä¢ [API Docs](#API-Docs) ‚Ä¢ [Architecture](#Architecture) ‚Ä¢ [Performance](#Performance)

</div>

---

## üåü Overview

**Arbeit** is an intelligent job monitoring platform that aggregates remote job postings from multiple sources, filters out spam and low-quality listings, and matches opportunities to user preferences using advanced algorithms.

### Current Metrics

- üîç **584+ jobs** scraped from **6 active sources**
- üõ°Ô∏è **47.4% spam/low-quality jobs** automatically filtered
- üéØ **Intelligent matching** with relevance scoring
- ‚ö° **<100ms** average search response time
- ‚úÖ **50 tests** with 100% pass rate and 90% coverage

---

## üöÄ Key Features

### ü§ñ Automated Job Scraping
- **Multi-Source Aggregation**: RemoteOK, WeWorkRemotely, RealWorkFromAnywhere, Himalayas, Jobicy, Remotive
- **RSS Feed Integration**: Standardized parsing across all sources
- **Intelligent Deduplication**: Fuzzy matching to eliminate duplicate listings
- **Scheduled Updates**: Celery-based task scheduling with automatic retries
- **Current Stats**: 584+ jobs scraped with 101 from RemoteOK, 228 from RealWorkFromAnywhere, 91 from Himalayas

### üõ°Ô∏è Quality Filtering System
- **Spam Detection**: 21 suspicious keyword patterns + 8 malicious domain blocklist
- **5-Factor Quality Scoring**: Company info, description quality, location, salary transparency, title clarity
- **Automatic Filtering**: Jobs scoring <0.6 are automatically excluded
- **Real Results**: 358 high-quality jobs (52.6%) retained, 193 low-quality (28.4%) filtered, 129 spam (19.0%) blocked

### üéØ Intelligent Matching Engine
- **Weighted Keyword Matching**: Title matches weighted 2x, description 1x
- **Fuzzy Location Matching**: 85% similarity threshold using RapidFuzz
- **Salary Range Compatibility**: Smart overlap detection with NULL handling
- **Bonus Scoring**: Additional points for salary transparency, remote work, recency, quality
- **Relevance Scores**: 0.0-1.0 scoring with detailed match explanations

### üë§ User Preference System
- **Flexible Criteria**: Keywords, excluded terms, location, salary range, remote preference, job types
- **Notification Settings**: Realtime, daily, or weekly digest options
- **Full CRUD API**: Complete preference management with validation

### üîê Secure Authentication
- **JWT-based Auth**: Access and refresh token flow
- **Email Verification**: Secure account activation
- **Password Hashing**: bcrypt with secure salt rounds
- **Rate Limiting**: Protection against brute force attacks

---

## üõ†Ô∏è Tech Stack

### Backend Framework
- **FastAPI** - Modern, high-performance Python web framework
- **Uvicorn** - Lightning-fast ASGI server
- **Pydantic** - Data validation and settings management

### Database & Caching
- **PostgreSQL 15** - Primary relational database
- **SQLAlchemy 2.0** - ORM with async support
- **Alembic** - Database migration management
- **Redis 7** - Caching and message broker

### Task Queue & Scheduling
- **Celery 5.3** - Distributed task queue
- **Celery Beat** - Periodic task scheduler
- **Flower** - Real-time Celery monitoring UI

### Scraping & Processing
- **HTTPX** - Modern async HTTP client
- **BeautifulSoup4** - HTML parsing
- **Feedparser** - RSS/Atom feed parsing
- **RapidFuzz** - Fast fuzzy string matching

### DevOps & Testing
- **Docker & Docker Compose** - Containerization
- **Pytest** - Testing framework with 90% coverage
- **Black, isort, flake8** - Code formatting and linting
- **MyPy** - Static type checking

---

## ‚ö° Quick Start

### Prerequisites

```bash
# Required
- Docker & Docker Compose
- Python 3.11+
- Git
```

### Installation

**1. Clone the repository**

```bash
git clone https://github.com/yourusername/arbeit-backend.git
cd arbeit-backend
```

**2. Configure environment**

```bash
cp .env.example .env.local
# Generate JWT secret
openssl rand -hex 32  # Copy output to JWT_SECRET in .env.local
```

**3. Start all services**

```bash
docker-compose up -d
```

**4. Run database migrations**

```bash
docker-compose exec app alembic upgrade head
```

**5. Access the application**

- üìö **API Documentation**: http://localhost:8000/docs
- üìñ **ReDoc**: http://localhost:8000/redoc
- üå∏ **Flower Dashboard**: http://localhost:5555
- ‚ù§Ô∏è **Health Check**: http://localhost:8000/health

---

## üèóÔ∏è Architecture

```mermaid
graph TB
    subgraph "External Sources"
        S1[RemoteOK]
        S2[WeWorkRemotely]
        S3[Himalayas]
        S4[Jobicy]
        S5[Remotive]
        S6[RealWorkFromAnywhere]
    end
    
    subgraph "Data Pipeline"
        Scraper[Celery Scrapers]
        Dedup[Deduplication Engine]
        Quality[Quality Filter]
    end
    
    subgraph "Core Services"
        API[FastAPI REST API]
        Matcher[Matching Engine]
        Auth[JWT Authentication]
    end
    
    subgraph "Data Layer"
        PG[(PostgreSQL)]
        Redis[(Redis Cache)]
    end
    
    subgraph "Clients"
        Web[Web Frontend]
        Mobile[Mobile App]
    end
    
    S1 & S2 & S3 & S4 & S5 & S6 --> Scraper
    Scraper --> Dedup --> Quality --> PG
    PG --> Matcher --> API
    Redis --> API
    Auth --> API
    API --> Web & Mobile
```

### System Components

- **Scrapers**: Celery workers that fetch jobs from RSS feeds every 6 hours
- **Deduplication**: Fuzzy matching algorithm to identify duplicate listings
- **Quality Filter**: ML-inspired scoring system to filter spam and low-quality posts
- **Matching Engine**: Personalized job recommendation based on user preferences
- **REST API**: FastAPI endpoints for authentication, preferences, and job search
- **Task Queue**: Celery + Redis for background job processing

---

## üìö API Documentation

### Authentication Endpoints

| Method | Endpoint | Description | Auth Required |
|--------|----------|-------------|---------------|
| POST | `/api/auth/register` | Register new user | ‚ùå |
| POST | `/api/auth/login` | Login and get JWT tokens | ‚ùå |
| GET | `/api/auth/verify-email` | Verify email address | ‚ùå |

### User Preferences

| Method | Endpoint | Description | Auth Required |
|--------|----------|-------------|---------------|
| POST | `/api/preferences` | Create/update preferences | ‚úÖ |
| GET | `/api/preferences` | Get user preferences | ‚úÖ |
| PATCH | `/api/preferences` | Partial update | ‚úÖ |
| DELETE | `/api/preferences` | Delete preferences | ‚úÖ |

### Job Search

| Method | Endpoint | Description | Auth Required |
|--------|----------|-------------|---------------|
| GET | `/api/jobs/search` | Search jobs with filters | ‚ùå |
| GET | `/api/jobs/{job_id}` | Get specific job | ‚ùå |
| GET | `/api/jobs/matched` | Get personalized matches | ‚úÖ |

### Admin

| Method | Endpoint | Description | Auth Required |
|--------|----------|-------------|---------------|
| POST | `/admin/scrape-all` | Trigger scraping for all sources | ‚úÖ (Admin) |
| POST | `/admin/scrape/{source}` | Trigger scraping for one source | ‚úÖ (Admin) |

### Example: Search Jobs

```bash
curl "http://localhost:8000/api/jobs/search?keywords=Python,FastAPI&location=Remote&min_salary=80000&remote=true&limit=10"
```

### Example: Get Matched Jobs

```bash
curl -X GET "http://localhost:8000/api/jobs/matched?min_score=0.6" \
  -H "Authorization: Bearer YOUR_JWT_TOKEN"
```

**Response:**

```json
{
  "jobs": [
    {
      "id": "123e4567-e89b-12d3-a456-426614174000",
      "title": "Senior Python Developer",
      "company": "TechCorp",
      "location": "Remote",
      "salary_min": 90000,
      "salary_max": 130000,
      "relevance_score": 0.87,
      "match_reasons": ["Python keyword match", "Remote preference", "Salary in range"],
      "quality_score": 0.92,
      "posted_at": "2024-10-30T10:00:00Z"
    }
  ],
  "total": 42,
  "limit": 10,
  "offset": 0
}
```

---

## üß™ Testing

### Run All Tests

```bash
docker-compose exec app pytest -v
```

### Run Specific Test Suites

```bash
# Quality filtering tests
docker-compose exec app pytest tests/test_quality_filter.py -v

# Matching engine tests
docker-compose exec app pytest tests/test_matching.py -v

# API integration tests
docker-compose exec app pytest tests/test_preferences_api.py tests/test_jobs_api.py -v
```

### Coverage Report

```bash
docker-compose exec app pytest --cov=app --cov-report=html
# Open htmlcov/index.html in browser
```

### Test Results

- ‚úÖ **50 tests** across 4 test suites
- ‚úÖ **100% pass rate**
- ‚úÖ **~90% code coverage**
- ‚úÖ **10 quality filter tests**
- ‚úÖ **19 matching engine tests**
- ‚úÖ **8 preferences API tests**
- ‚úÖ **13 jobs API tests**

---

## üìÅ Project Structure

```bash
arbeit-backend/
‚îú‚îÄ‚îÄ üìÅ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/           # CI/CD pipelines
‚îú‚îÄ‚îÄ üìÅ alembic/
‚îÇ   ‚îî‚îÄ‚îÄ versions/            # Database migrations
‚îú‚îÄ‚îÄ üìÅ app/
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ api/              # REST API endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auth.py          # Authentication routes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ admin.py         # Admin routes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ preferences.py   # User preferences CRUD
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ jobs.py          # Job search & matching
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ core/             # Core configuration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py        # Settings management
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database.py      # DB connection
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ security.py      # JWT & password hashing
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ scrapers/         # Job source scrapers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py          # Base scraper class
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ remoteok.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ weworkremotely.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ himalayas.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ jobicy.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ remotive.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ realworkfromanywhere.py
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ services/         # Business logic
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ quality_filter.py # Quality & spam detection
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ utils/            # Utility functions
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ deduplication.py # Job deduplication
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ matching.py      # Matching engine
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ schemas/          # Pydantic schemas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ job.py           # Job schemas
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ preference.py    # Preference schemas
‚îÇ   ‚îú‚îÄ‚îÄ celery_app.py        # Celery configuration
‚îÇ   ‚îú‚îÄ‚îÄ models.py            # SQLAlchemy models
‚îÇ   ‚îú‚îÄ‚îÄ main.py              # FastAPI application
‚îÇ   ‚îú‚îÄ‚îÄ scheduler.py         # Celery Beat scheduler
‚îÇ   ‚îú‚îÄ‚îÄ tasks.py             # Celery tasks
‚îÇ   ‚îî‚îÄ‚îÄ logging_config.py    # Logging setup
‚îú‚îÄ‚îÄ üìÅ tests/               # Test suite
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py          # Test fixtures
‚îÇ   ‚îú‚îÄ‚îÄ test_quality_filter.py
‚îÇ   ‚îú‚îÄ‚îÄ test_matching.py
‚îÇ   ‚îú‚îÄ‚îÄ test_preferences_api.py
‚îÇ   ‚îî‚îÄ‚îÄ test_jobs_api.py
‚îú‚îÄ‚îÄ .env.example         # Environment template
‚îú‚îÄ‚îÄ docker-compose.yml   # Docker orchestration
‚îú‚îÄ‚îÄ Dockerfile           # Container definition
‚îú‚îÄ‚îÄ requirements.txt     # Python dependencies
‚îî‚îÄ‚îÄ README.md            # Documentation
```

---

## ‚ö° Performance

### Response Times

| Operation | Average | P95 | P99 |
|-----------|---------|-----|-----|
| Job Search (Public) | <100ms | 150ms | 200ms |
| Matched Jobs (Personalized) | <200ms | 300ms | 400ms |
| Quality Filtering | <50ms | 75ms | 100ms |
| Authentication | <50ms | 80ms | 120ms |

### Database Performance

- **Optimized Indexes**: quality_score, location, salary_min, salary_max, posted_at
- **Connection Pooling**: SQLAlchemy async pool with 20 connections
- **Query Optimization**: N+1 query prevention with eager loading

### Scraping Performance

- **6 sources** scraped in parallel
- **~100 jobs/minute** processing rate
- **Automatic retry** with exponential backoff
- **Timeout handling**: 30s per source

---

## üìù License

This project is licensed under the MIT License.

---

## üë§ Contact & Contributing

Interested in contributing or learning more about this project? Feel free to reach out!

**Built with ‚ù§Ô∏è using FastAPI, PostgreSQL, and modern Python best practices.**
